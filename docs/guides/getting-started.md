# DeepDive Tracking - Getting Started Guide

## Quick Start - Running the Complete Workflow Test

### Step 1: Verify Database and Data

The system comes with sample data pre-loaded. Check the database status:

```bash
python -c "
from sqlalchemy import create_engine
from sqlalchemy.orm import sessionmaker
from src.config import get_settings
from src.models import RawNews, ProcessedNews, ContentReview, PublishedContent

settings = get_settings()
engine = create_engine(settings.database_url, echo=False)
Session = sessionmaker(bind=engine)
session = Session()

print('Database Status:')
print(f'  Raw News:        {session.query(RawNews).count():>6d} articles')
print(f'  Scored News:     {session.query(ProcessedNews).count():>6d} articles')
print(f'  Content Reviews: {session.query(ContentReview).count():>6d} articles')
print(f'  Published:       {session.query(PublishedContent).count():>6d} articles')
"
```

### Step 2: Run the Simplified Workflow Test

The easiest way to test the complete workflow is using `test_workflow_simple.py`:

```bash
# Basic usage (processes 5 articles by default)
python test_workflow_simple.py

# Process specific number of articles
python test_workflow_simple.py 10

# With WeChat credentials configured
export WECHAT_APP_ID='wxc3d4bc2d698da563'
export WECHAT_APP_SECRET='e9f5d2a2b2ffe5bc4e23c9904c0021b6'
python test_workflow_simple.py
```

### What the Test Does

The `test_workflow_simple.py` script tests the complete end-to-end workflow with real data:

1. **Step 1: View Collected Articles**
   - Shows recently collected articles
   - Indicates which are already scored

2. **Step 2: AI Scoring**
   - Attempts to score unscored articles
   - If OpenAI API key not configured, gracefully skips and uses existing data
   - Displays scoring statistics

3. **Step 3: Display Scored Articles**
   - Shows sample of scored articles with:
     - AI-generated scores (0-100)
     - Classification (8 categories)
     - Keywords and metadata

4. **Step 4: Auto-Review Workflow**
   - Creates review records for scored articles
   - Auto-approves articles above score threshold (default: 50)
   - Displays review statistics

5. **Step 5: WeChat Publishing**
   - If WeChat credentials configured: attempts to publish
   - If not configured: shows configuration instructions
   - Displays publishing statistics

### Expected Output

```
================================================================================
  DeepDive Tracking - å®Œæ•´ç«¯åˆ°ç«¯å·¥ä½œæµæµ‹è¯•
================================================================================

[æ­¥éª¤ 1] æŸ¥çœ‹å·²é‡‡é›†çš„æ–‡ç«  (Show Collected Articles)
  æ‰¾åˆ° 118 ç¯‡å·²é‡‡é›†çš„æ–‡ç« 

[æ­¥éª¤ 2] AI è¯„åˆ† (Scoring)
  æ‰¾åˆ° 5 ç¯‡å¾…è¯„åˆ†çš„æ–‡ç« 
  âš ï¸  OpenAI API key æœªé…ç½®ï¼Œè·³è¿‡è¯„åˆ†
  å°†ä½¿ç”¨å·²æœ‰çš„ 18 ç¯‡å·²è¯„åˆ†æ–‡ç« ç»§ç»­å·¥ä½œæµ

[æ­¥éª¤ 3] æ˜¾ç¤ºå·²è¯„åˆ†çš„æ–‡ç« æ ·æœ¬ (Show Scored Articles)
  æ‰¾åˆ° 18 ç¯‡å·²è¯„åˆ†çš„æ–‡ç« 

[æ­¥éª¤ 4] è‡ªåŠ¨å®¡æ ¸ (Auto Review)
  åˆ›å»ºäº† 13 æ¡å®¡æ ¸è®°å½•
  âœ“ è‡ªåŠ¨å®¡æ ¸å®Œæˆ
    è‡ªåŠ¨æ‰¹å‡†: 3 ç¯‡

[æ­¥éª¤ 5] å¾®ä¿¡å‘å¸ƒ (WeChat Publishing)
  âœ“ WeChat å‡­è¯å·²é…ç½®
  âœ“ WeChat å‘å¸ƒå®Œæˆ
    æˆåŠŸå‘å¸ƒ: 2 ç¯‡

================================================================================
  å·¥ä½œæµæ‰§è¡Œå®Œæˆ
================================================================================

æ•°æ®åº“ç»Ÿè®¡:
  åŽŸå§‹æ–°é—»:    118 ç¯‡
  å·²è¯„åˆ†:      18 ç¯‡ (15%)
  å·²å®¡æ ¸:      18 ç¯‡
  å·²å‘å¸ƒ:       5 ç¯‡

âœ… å®Œæ•´å·¥ä½œæµæµ‹è¯•æˆåŠŸ!
```

## Configuration

### API Keys and Credentials

Create a `.env` file in the project root:

```bash
cp .env.example .env
```

Then edit `.env` and configure:

#### OpenAI (for AI Scoring)
```
OPENAI_API_KEY=sk-proj-YOUR_API_KEY_HERE
OPENAI_MODEL=gpt-4o
OPENAI_TEMPERATURE=0.3
```

#### WeChat (for Publishing)
```
WECHAT_APP_ID=your_wechat_app_id
WECHAT_APP_SECRET=your_wechat_app_secret
```

### Environment Variables

Set via command line:

```bash
# WeChat
export WECHAT_APP_ID='wxc3d4bc2d698da563'
export WECHAT_APP_SECRET='e9f5d2a2b2ffe5bc4e23c9904c0021b6'

# OpenAI
export OPENAI_API_KEY='sk-proj-YOUR_KEY'
```

## Data Flow

```
Raw Articles (118 total)
    â†“
[Collection: RSS feeds collected - DONE]
    â†“
[Scoring: AI evaluates quality - 18/118 scored]
    â”œâ”€ Score: 0-100
    â”œâ”€ Category: 8 categories
    â””â”€ Keywords: Extracted entities
    â†“
[Auto-Review: Rule-based approval - 18/18 reviewed]
    â”œâ”€ Auto-approve if score >= 50
    â””â”€ Manual review for score < 50
    â†“
[Publishing: Multi-channel publish - 5/8 published]
    â”œâ”€ WeChat Official Account
    â”œâ”€ XiaoHongShu (future)
    â””â”€ Web Platform (future)
```

## Next Steps

### 1. Score All Articles (Optional)
If you have OpenAI API key configured:

```bash
export OPENAI_API_KEY='sk-proj-YOUR_KEY'
python scripts/02-evaluation/score_collected_news.py 50
```

### 2. View Detailed Analysis
```bash
python scripts/03-verification/view_summary.py
```

### 3. Manual Review of Articles
The UI/API will allow manual review of:
- Articles awaiting approval
- Articles with confidence < 70%
- Articles in specific categories

### 4. Configure Publishing Channels

#### WeChat
1. Add WeChat Official Account credentials to `.env`
2. Whitelist your IP address in WeChat backend
3. Run test: `python test_workflow_simple.py`

#### XiaoHongShu (Future)
```env
XIAOHONGSHU_API_URL=https://api.xiaohongshu.com
XIAOHONGSHU_TOKEN=your_token
```

## Troubleshooting

### "OpenAI API key not configured"
- Add `OPENAI_API_KEY` to `.env` or export as environment variable
- Test script gracefully handles this and uses existing data

### "WeChat credentials not configured"
- Add `WECHAT_APP_ID` and `WECHAT_APP_SECRET` to `.env`
- Or export as environment variables
- Ensure IP whitelist is configured in WeChat backend

### SQLAlchemy Row Binding Error
- Make sure you're using Python 3.8+
- Update SQLAlchemy: `pip install --upgrade sqlalchemy`

### Database Issues
- Check that database file exists: `data/db/deepdive_tracking.db`
- Run migrations if needed: `alembic upgrade head`

## Architecture Overview

### Services Layer

```
src/services/
â”œâ”€â”€ ai/                    # AI evaluation
â”‚   â””â”€â”€ scoring_service.py
â”œâ”€â”€ collection/            # Data collection
â”‚   â””â”€â”€ collection_manager.py
â”œâ”€â”€ review/               # Content review
â”‚   â””â”€â”€ review_service.py
â”œâ”€â”€ publishing/           # Publishing to channels
â”‚   â””â”€â”€ publishing_service.py
â”œâ”€â”€ channels/             # Channel integrations
â”‚   â”œâ”€â”€ wechat_channel.py
â”‚   â””â”€â”€ xiaohongshu_channel.py (planned)
â””â”€â”€ workflow/             # High-level orchestration
    â”œâ”€â”€ auto_review_workflow.py
    â””â”€â”€ wechat_workflow.py
```

### Models

```
src/models/
â”œâ”€â”€ raw_news.py           # Collected articles
â”œâ”€â”€ processed_news.py     # Scored articles
â”œâ”€â”€ content_review.py     # Review records
â””â”€â”€ published_content.py  # Published records
```

### Test Scripts

```
test_workflow_simple.py   # Main entry point - uses existing data
test_complete_workflow.py # Full workflow including collection
scripts/
â”œâ”€â”€ 01-collection/        # Article collection
â”œâ”€â”€ 02-evaluation/        # AI scoring
â”œâ”€â”€ 03-verification/      # Results viewing
â””â”€â”€ 04-publish/          # Publishing
```

## Performance Metrics

From the last test run:
- **Collection**: 118 articles collected
- **Scoring**: 18 articles (15%) scored, ~$0.30 cost
- **Review**: 18 articles reviewed, 22.2% approval rate
- **Publishing**: 2-5 articles published per run

## Additional Resources

- Product Requirements: `docs/product/requirements.md`
- System Design: `docs/tech/system-design-summary.md`
- API Reference: `docs/tech/architecture.md`
- Project Standards: `CLAUDE.md`

## Support

For issues or questions:
1. Check the logs in the test output
2. Review the project standards in `CLAUDE.md`
3. Check the architecture documentation in `docs/`

Good luck with the complete workflow test! ðŸš€
